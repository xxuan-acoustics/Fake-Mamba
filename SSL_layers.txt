Model Layers:
Layer:  | Type: <class 'fairseq.models.wav2vec.wav2vec2.Wav2Vec2Model'>
Layer: feature_extractor | Type: <class 'fairseq.models.wav2vec.wav2vec2.ConvFeatureExtractionModel'>
Layer: feature_extractor.conv_layers | Type: <class 'torch.nn.modules.container.ModuleList'>
Layer: feature_extractor.conv_layers.0 | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: feature_extractor.conv_layers.0.0 | Type: <class 'torch.nn.modules.conv.Conv1d'>
Layer: feature_extractor.conv_layers.0.1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: feature_extractor.conv_layers.0.2 | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: feature_extractor.conv_layers.0.2.0 | Type: <class 'fairseq.modules.transpose_last.TransposeLast'>
Layer: feature_extractor.conv_layers.0.2.1 | Type: <class 'fairseq.modules.layer_norm.Fp32LayerNorm'>
Layer: feature_extractor.conv_layers.0.2.2 | Type: <class 'fairseq.modules.transpose_last.TransposeLast'>
Layer: feature_extractor.conv_layers.0.3 | Type: <class 'torch.nn.modules.activation.GELU'>
Layer: feature_extractor.conv_layers.1 | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: feature_extractor.conv_layers.1.0 | Type: <class 'torch.nn.modules.conv.Conv1d'>
Layer: feature_extractor.conv_layers.1.1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: feature_extractor.conv_layers.1.2 | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: feature_extractor.conv_layers.1.2.0 | Type: <class 'fairseq.modules.transpose_last.TransposeLast'>
Layer: feature_extractor.conv_layers.1.2.1 | Type: <class 'fairseq.modules.layer_norm.Fp32LayerNorm'>
Layer: feature_extractor.conv_layers.1.2.2 | Type: <class 'fairseq.modules.transpose_last.TransposeLast'>
Layer: feature_extractor.conv_layers.1.3 | Type: <class 'torch.nn.modules.activation.GELU'>
Layer: feature_extractor.conv_layers.2 | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: feature_extractor.conv_layers.2.0 | Type: <class 'torch.nn.modules.conv.Conv1d'>
Layer: feature_extractor.conv_layers.2.1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: feature_extractor.conv_layers.2.2 | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: feature_extractor.conv_layers.2.2.0 | Type: <class 'fairseq.modules.transpose_last.TransposeLast'>
Layer: feature_extractor.conv_layers.2.2.1 | Type: <class 'fairseq.modules.layer_norm.Fp32LayerNorm'>
Layer: feature_extractor.conv_layers.2.2.2 | Type: <class 'fairseq.modules.transpose_last.TransposeLast'>
Layer: feature_extractor.conv_layers.2.3 | Type: <class 'torch.nn.modules.activation.GELU'>
Layer: feature_extractor.conv_layers.3 | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: feature_extractor.conv_layers.3.0 | Type: <class 'torch.nn.modules.conv.Conv1d'>
Layer: feature_extractor.conv_layers.3.1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: feature_extractor.conv_layers.3.2 | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: feature_extractor.conv_layers.3.2.0 | Type: <class 'fairseq.modules.transpose_last.TransposeLast'>
Layer: feature_extractor.conv_layers.3.2.1 | Type: <class 'fairseq.modules.layer_norm.Fp32LayerNorm'>
Layer: feature_extractor.conv_layers.3.2.2 | Type: <class 'fairseq.modules.transpose_last.TransposeLast'>
Layer: feature_extractor.conv_layers.3.3 | Type: <class 'torch.nn.modules.activation.GELU'>
Layer: feature_extractor.conv_layers.4 | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: feature_extractor.conv_layers.4.0 | Type: <class 'torch.nn.modules.conv.Conv1d'>
Layer: feature_extractor.conv_layers.4.1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: feature_extractor.conv_layers.4.2 | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: feature_extractor.conv_layers.4.2.0 | Type: <class 'fairseq.modules.transpose_last.TransposeLast'>
Layer: feature_extractor.conv_layers.4.2.1 | Type: <class 'fairseq.modules.layer_norm.Fp32LayerNorm'>
Layer: feature_extractor.conv_layers.4.2.2 | Type: <class 'fairseq.modules.transpose_last.TransposeLast'>
Layer: feature_extractor.conv_layers.4.3 | Type: <class 'torch.nn.modules.activation.GELU'>
Layer: feature_extractor.conv_layers.5 | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: feature_extractor.conv_layers.5.0 | Type: <class 'torch.nn.modules.conv.Conv1d'>
Layer: feature_extractor.conv_layers.5.1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: feature_extractor.conv_layers.5.2 | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: feature_extractor.conv_layers.5.2.0 | Type: <class 'fairseq.modules.transpose_last.TransposeLast'>
Layer: feature_extractor.conv_layers.5.2.1 | Type: <class 'fairseq.modules.layer_norm.Fp32LayerNorm'>
Layer: feature_extractor.conv_layers.5.2.2 | Type: <class 'fairseq.modules.transpose_last.TransposeLast'>
Layer: feature_extractor.conv_layers.5.3 | Type: <class 'torch.nn.modules.activation.GELU'>
Layer: feature_extractor.conv_layers.6 | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: feature_extractor.conv_layers.6.0 | Type: <class 'torch.nn.modules.conv.Conv1d'>
Layer: feature_extractor.conv_layers.6.1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: feature_extractor.conv_layers.6.2 | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: feature_extractor.conv_layers.6.2.0 | Type: <class 'fairseq.modules.transpose_last.TransposeLast'>
Layer: feature_extractor.conv_layers.6.2.1 | Type: <class 'fairseq.modules.layer_norm.Fp32LayerNorm'>
Layer: feature_extractor.conv_layers.6.2.2 | Type: <class 'fairseq.modules.transpose_last.TransposeLast'>
Layer: feature_extractor.conv_layers.6.3 | Type: <class 'torch.nn.modules.activation.GELU'>
Layer: post_extract_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: dropout_input | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: dropout_features | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: quantizer | Type: <class 'fairseq.modules.gumbel_vector_quantizer.GumbelVectorQuantizer'>
Layer: quantizer.weight_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: project_q | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerEncoder'>
Layer: encoder.pos_conv | Type: <class 'torch.nn.modules.container.Sequential'>
Layer: encoder.pos_conv.0 | Type: <class 'torch.nn.modules.conv.Conv1d'>
Layer: encoder.pos_conv.1 | Type: <class 'fairseq.modules.same_pad.SamePad'>
Layer: encoder.pos_conv.2 | Type: <class 'torch.nn.modules.activation.GELU'>
Layer: encoder.layers | Type: <class 'torch.nn.modules.container.ModuleList'>
Layer: encoder.layers.0 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.0.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.0.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.0.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.0.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.0.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.0.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.0.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.0.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.0.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.0.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.0.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.0.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.0.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.1 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.1.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.1.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.1.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.1.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.1.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.1.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.1.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.1.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.1.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.1.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.1.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.1.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.1.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.2 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.2.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.2.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.2.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.2.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.2.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.2.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.2.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.2.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.2.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.2.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.2.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.2.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.2.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.3 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.3.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.3.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.3.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.3.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.3.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.3.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.3.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.3.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.3.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.3.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.3.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.3.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.3.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.4 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.4.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.4.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.4.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.4.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.4.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.4.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.4.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.4.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.4.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.4.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.4.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.4.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.4.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.5 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.5.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.5.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.5.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.5.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.5.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.5.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.5.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.5.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.5.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.5.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.5.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.5.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.5.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.6 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.6.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.6.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.6.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.6.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.6.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.6.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.6.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.6.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.6.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.6.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.6.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.6.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.6.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.7 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.7.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.7.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.7.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.7.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.7.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.7.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.7.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.7.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.7.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.7.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.7.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.7.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.7.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.8 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.8.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.8.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.8.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.8.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.8.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.8.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.8.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.8.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.8.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.8.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.8.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.8.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.8.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.9 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.9.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.9.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.9.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.9.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.9.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.9.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.9.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.9.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.9.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.9.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.9.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.9.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.9.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.10 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.10.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.10.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.10.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.10.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.10.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.10.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.10.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.10.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.10.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.10.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.10.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.10.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.10.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.11 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.11.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.11.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.11.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.11.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.11.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.11.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.11.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.11.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.11.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.11.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.11.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.11.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.11.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.12 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.12.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.12.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.12.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.12.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.12.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.12.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.12.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.12.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.12.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.12.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.12.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.12.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.12.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.13 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.13.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.13.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.13.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.13.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.13.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.13.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.13.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.13.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.13.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.13.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.13.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.13.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.13.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.14 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.14.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.14.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.14.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.14.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.14.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.14.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.14.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.14.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.14.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.14.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.14.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.14.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.14.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.15 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.15.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.15.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.15.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.15.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.15.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.15.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.15.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.15.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.15.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.15.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.15.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.15.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.15.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.16 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.16.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.16.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.16.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.16.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.16.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.16.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.16.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.16.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.16.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.16.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.16.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.16.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.16.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.17 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.17.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.17.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.17.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.17.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.17.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.17.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.17.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.17.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.17.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.17.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.17.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.17.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.17.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.18 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.18.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.18.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.18.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.18.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.18.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.18.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.18.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.18.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.18.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.18.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.18.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.18.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.18.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.19 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.19.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.19.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.19.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.19.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.19.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.19.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.19.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.19.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.19.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.19.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.19.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.19.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.19.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.20 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.20.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.20.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.20.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.20.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.20.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.20.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.20.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.20.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.20.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.20.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.20.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.20.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.20.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.21 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.21.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.21.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.21.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.21.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.21.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.21.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.21.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.21.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.21.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.21.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.21.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.21.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.21.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.22 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.22.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.22.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.22.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.22.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.22.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.22.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.22.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.22.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.22.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.22.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.22.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.22.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.22.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.23 | Type: <class 'fairseq.models.wav2vec.wav2vec2.TransformerSentenceEncoderLayer'>
Layer: encoder.layers.23.self_attn | Type: <class 'fairseq.modules.multihead_attention.MultiheadAttention'>
Layer: encoder.layers.23.self_attn.dropout_module | Type: <class 'fairseq.modules.fairseq_dropout.FairseqDropout'>
Layer: encoder.layers.23.self_attn.k_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.23.self_attn.v_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.23.self_attn.q_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.23.self_attn.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.23.dropout1 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.23.dropout2 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.23.dropout3 | Type: <class 'torch.nn.modules.dropout.Dropout'>
Layer: encoder.layers.23.self_attn_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layers.23.fc1 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.23.fc2 | Type: <class 'torch.nn.modules.linear.Linear'>
Layer: encoder.layers.23.final_layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: encoder.layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: layer_norm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>
Layer: final_proj | Type: <class 'torch.nn.modules.linear.Linear'>
